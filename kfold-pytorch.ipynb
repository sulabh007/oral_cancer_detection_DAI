{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7599778,"sourceType":"datasetVersion","datasetId":4423968}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    from torchinfo import summary\nexcept:\n    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n    !pip install -q torchinfo\n    from torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:09.489738Z","iopub.execute_input":"2024-02-11T13:18:09.490597Z","iopub.status.idle":"2024-02-11T13:18:13.136359Z","shell.execute_reply.started":"2024-02-11T13:18:09.490561Z","shell.execute_reply":"2024-02-11T13:18:13.135386Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nfrom pathlib import Path\n\nimport re\nimport random\nimport matplotlib.pyplot as plt\nimport math\nimport torch\n\nfrom PIL import Image\nfrom pandas import DataFrame\nfrom typing import Tuple, Dict, List\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\nfrom sklearn.model_selection import StratifiedKFold\n\n\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nfrom torchinfo import summary\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:13.138139Z","iopub.execute_input":"2024-02-11T13:18:13.138898Z","iopub.status.idle":"2024-02-11T13:18:17.595376Z","shell.execute_reply.started":"2024-02-11T13:18:13.138864Z","shell.execute_reply":"2024-02-11T13:18:17.594585Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = Path('/kaggle/input/oral-dataset/patches')\ndir_list = os.listdir(data_path)\nprint(\"Files and directories in '\", data_path, \"' :\")\n# prints all files\nprint(dir_list)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.596468Z","iopub.execute_input":"2024-02-11T13:18:17.597071Z","iopub.status.idle":"2024-02-11T13:18:17.607164Z","shell.execute_reply.started":"2024-02-11T13:18:17.597043Z","shell.execute_reply":"2024-02-11T13:18:17.606323Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Files and directories in ' /kaggle/input/oral-dataset/patches ' :\n['sabpatch_parsed_test.csv', 'images', 'sabpatch_parsed_folders.csv']\n","output_type":"stream"}]},{"cell_type":"code","source":"image_dir = data_path / 'images'\ntrain_df = pd.read_csv(data_path/'sabpatch_parsed_folders.csv')\ntrain_ds = train_df[['path','lesion']]\ntest_df = pd.read_csv(data_path/'sabpatch_parsed_test.csv')\ntest_ds = test_df[['path','lesion']]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.609286Z","iopub.execute_input":"2024-02-11T13:18:17.609602Z","iopub.status.idle":"2024-02-11T13:18:17.639835Z","shell.execute_reply.started":"2024-02-11T13:18:17.609578Z","shell.execute_reply":"2024-02-11T13:18:17.639134Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ALPHA = 0.00005 ## Learning Rate\nEPOCH = 10  ## Epochs\nBATCH_SIZE = 32\nK_FOLDS = 5\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.640923Z","iopub.execute_input":"2024-02-11T13:18:17.641512Z","iopub.status.idle":"2024-02-11T13:18:17.676827Z","shell.execute_reply.started":"2024-02-11T13:18:17.641480Z","shell.execute_reply":"2024-02-11T13:18:17.675322Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Write a custom dataset class (inherits from torch.utils.data.Dataset)\nclass ImageFolderCustom(Dataset):\n\n    # 1. Initialize with a targ_dir and transform (optional) parameter\n    def __init__(self,\n                 targ_dir: str,\n                 path_df: DataFrame,\n                 transform=None) -> None:\n\n        # Get all image paths, classes\n        self.img_df = path_df\n\n        # Set all images to proper path\n        self.img_df['path'] = self.check_path(targ_dir)\n\n        self.paths = list(self.img_df['path'])\n\n        # Setup transforms\n        self.transform = transform\n\n        self.classes, self.class_to_idx = self.find_classes()\n\n    # 2. check if its already in proper format\n    def check_path(self,\n                   targ_dir: str) -> DataFrame:\n        if str(targ_dir) in self.img_df.iloc[0,0]:\n            return self.img_df['path'].astype('string')\n        else:\n            return str(targ_dir)+ '/' +  self.img_df['path'].astype('string')\n\n    # 3. Make function to load images\n    def load_image(self,\n                   index: int) -> Image.Image:\n        \"Opens an image via a path and returns it.\"\n        image_path = self.img_df.iloc[index, 0]\n        return Image.open(image_path)\n\n    # 4. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n    def __len__(self) -> int:\n        \"Returns the total number of samples.\"\n        return self.img_df.shape[0]\n\n    # 5. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n    def __getitem__(self,\n                    index: int) -> Tuple[torch.Tensor, int]:\n        \"Returns one sample of data, data and label (X, y).\"\n        img = self.load_image(index)\n        class_name  = self.img_df.iloc[index, 1] # expects path in data_folder/class_name/image.jpeg\n        class_idx = self.class_to_idx[class_name]\n\n        # Transform if necessary\n        if self.transform:\n            return self.transform(img), class_idx # return data, label (X, y)\n        else:\n            return img, class_idx # return data, label (X, y)\n\n\n    def find_classes(self) -> Tuple[List[str], Dict[str, int]]:\n\n        col = self.img_df.columns\n        # 1. Get the class names by scanning the target directory\n        classes = sorted(self.img_df[col[1]].unique())\n\n        # 2. Raise an error if class names not found\n        if not classes:\n            raise FileNotFoundError(f\"Couldn't find any classes.\")\n\n        # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.678000Z","iopub.execute_input":"2024-02-11T13:18:17.678295Z","iopub.status.idle":"2024-02-11T13:18:17.690959Z","shell.execute_reply.started":"2024-02-11T13:18:17.678245Z","shell.execute_reply":"2024-02-11T13:18:17.690073Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"manual_transforms = transforms.Compose([\n        transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n        transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n        transforms.Normalize(mean = MEAN, # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n                         std = STD)\n    ])\n\n\n\n    # test_transforms = transforms.Compose([\n    #     #transforms.Resize((64, 64)),\n    #     transforms.ToTensor(),\n    # ])\n\n\ntrain_data = ImageFolderCustom(targ_dir = image_dir,\n                                          path_df = train_ds,\n                                          transform= manual_transforms)\n\ntest_data = ImageFolderCustom(targ_dir = image_dir,\n                                          path_df = test_ds,\n                                          transform= manual_transforms)\n\nclasses, class_to_idx = train_data.find_classes()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.692198Z","iopub.execute_input":"2024-02-11T13:18:17.692631Z","iopub.status.idle":"2024-02-11T13:18:17.717456Z","shell.execute_reply.started":"2024-02-11T13:18:17.692600Z","shell.execute_reply":"2024-02-11T13:18:17.716406Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1968766816.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.img_df['path'] = self.check_path(targ_dir)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True).to(device)\n\n# for param in model.parameters():\n#     param.requires_grad = False\n\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 3)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:17.718805Z","iopub.execute_input":"2024-02-11T13:18:17.719554Z","iopub.status.idle":"2024-02-11T13:18:19.249047Z","shell.execute_reply.started":"2024-02-11T13:18:17.719523Z","shell.execute_reply":"2024-02-11T13:18:19.248324Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 150MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndef reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n    if hasattr(layer, 'reset_parameters'):\n#         print(f'Reset trainable parameters of layer = {layer}')\n        layer.reset_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.250372Z","iopub.execute_input":"2024-02-11T13:18:19.250660Z","iopub.status.idle":"2024-02-11T13:18:19.255657Z","shell.execute_reply.started":"2024-02-11T13:18:19.250636Z","shell.execute_reply":"2024-02-11T13:18:19.254769Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# loss_fn = nn.CrossEntropyLoss(reduction='sum') # computes the cross entropy loss between input logits and target.\n\n# optimizer = torch.optim.Adam(model.parameters(), lr = ALPHA)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.258976Z","iopub.execute_input":"2024-02-11T13:18:19.259239Z","iopub.status.idle":"2024-02-11T13:18:19.269075Z","shell.execute_reply.started":"2024-02-11T13:18:19.259217Z","shell.execute_reply":"2024-02-11T13:18:19.268225Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def train_epoch(model,device,dataloader,loss_fn,optimizer):\n#     train_loss,train_correct=0.0,0\n#     model.train()\n#     for images, labels in dataloader:\n\n#         images,labels = images.to(device),labels.to(device)\n#         optimizer.zero_grad()\n#         output = model(images)\n#         loss = loss_fn(output,labels)\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item() * images.size(0)\n#         scores, predictions = torch.max(output.data, 1)\n#         train_correct += (predictions == labels).sum().item()\n\n#     return train_loss,train_correct\n\n# def valid_epoch(model,device,dataloader,loss_fn):\n#     valid_loss, val_correct = 0.0, 0\n#     model.eval()\n#     with torch.no_grad():\n#         for images, labels in dataloader:\n#             images,labels = images.to(device),labels.to(device)\n#             output = model(images)\n#             loss=loss_fn(output,labels)\n#             valid_loss+=loss.item()*images.size(0)\n#             scores, predictions = torch.max(output.data,1)\n#             val_correct+=(predictions == labels).sum().item()\n\n#     return valid_loss,val_correct","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.270200Z","iopub.execute_input":"2024-02-11T13:18:19.270587Z","iopub.status.idle":"2024-02-11T13:18:19.279412Z","shell.execute_reply.started":"2024-02-11T13:18:19.270555Z","shell.execute_reply":"2024-02-11T13:18:19.278544Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# dataset = ConcatDataset([train_data, test_data])\n# labels = [t[1] for t in dataset]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.280711Z","iopub.execute_input":"2024-02-11T13:18:19.281050Z","iopub.status.idle":"2024-02-11T13:18:19.288969Z","shell.execute_reply.started":"2024-02-11T13:18:19.281010Z","shell.execute_reply":"2024-02-11T13:18:19.288098Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n\n\n\n\n# # Define the K-fold Cross Validator\n# kfold =  StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n#   # Start print\n# print('--------------------------------')\n\n# # K-fold Cross Validation model evaluation\n# for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset, labels)):\n#     print('Fold {}'.format(fold + 1))\n\n#     # Sample elements randomly from a given list of ids, no replacement.\n#     train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n#     test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n    \n#     # Define data loaders for training and testing data in this fold\n#     trainloader = torch.utils.data.DataLoader(\n#                       dataset, \n#                       batch_size=32, sampler=train_subsampler)\n#     testloader = torch.utils.data.DataLoader(\n#                       dataset,\n#                       batch_size=32, sampler=test_subsampler)\n    \n    \n#     model.to(device)\n#     optimizer = optim.Adam(model.parameters(), lr=0.002)\n\n#     for epoch in range(EPOCH):\n#         train_loss, train_correct=train_epoch(model,device,trainloader, loss_fn,optimizer)\n#         test_loss, test_correct=valid_epoch(model,device,testloader, loss_fn)\n\n#         train_loss = train_loss / len(trainloader.sampler)\n#         train_acc = train_correct / len(trainloader.sampler) * 100\n#         test_loss = test_loss / len(testloader.sampler)\n#         test_acc = test_correct / len(testloader.sampler) * 100\n\n#         print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n#                                                                                                              EPOCH,\n#                                                                                                              train_loss,\n#                                                                                                              test_loss,\n#                                                                                                              train_acc,\n#                                                                                                              test_acc))\n#         history['train_loss'].append(train_loss)\n#         history['test_loss'].append(test_loss)\n#         history['train_acc'].append(train_acc)\n#         history['test_acc'].append(test_acc)  ","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.290179Z","iopub.execute_input":"2024-02-11T13:18:19.290450Z","iopub.status.idle":"2024-02-11T13:18:19.299722Z","shell.execute_reply.started":"2024-02-11T13:18:19.290428Z","shell.execute_reply":"2024-02-11T13:18:19.298884Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KFold():\n#     wandb.init(\n#     project=\"ressnet50-v1\",\n#     config={\n#             \"epochs\": EPOCH,\n#             \"batch_size\": BATCH_SIZE,\n#             \"lr\": ALPHA,\n#             \"architecture\": \"CNN\",\n#             })\n\n    def __init__(self,\n                 model,\n                 loss_fn,\n                 optimizer,\n                 device,\n                 early_stopping = False):\n\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.device = device\n\n        self.early_stopping = early_stopping\n        self.counter = 0\n        self.early_stop = False # type: ignore\n        self.best_score = None\n\n#         # Copy your config\n#         self.config = wandb.config\n\n    def check_early_stop(self,\n                   val_loss,\n                   delta,\n                   verbose,\n                   patience,\n                   epoch):\n\n        score = -val_loss\n        # print(verbose)\n        if self.best_score is None:\n            self.best_score = score\n\n        elif score < self.best_score + delta and epoch < self.epochs:\n            self.counter += 1\n\n            if verbose:\n                print(f\"Early stopping counter: {self.counter} out of {patience}\")\n\n            if self.counter >= patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.early_stop = False\n            self.counter = 0\n            \n\n    def train_epoch(self, epoch):\n        \n        y_tr_true, y_tr_pred= [], []\n        train_loss = 0.0\n        \n        model.train()\n        for i, data in enumerate(tqdm(self.trainloader, desc=f'Epoch {epoch + 1}/{self.epochs}', unit='batch')):\n            \n            images, labels = data\n            y_tr_true.extend(labels) # collect all training labels\n            images,labels = images.to(device),labels.to(device)\n            \n            optimizer.zero_grad()\n            output = model(images)\n            loss = loss_fn(output,labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * images.size(0)\n            scores, predictions = torch.max(output.data, 1)\n            \n            y_tr_pred.extend(predictions)\n           \n        \n        train_correct =  accuracy_score(y_tr_true, y_tr_pred)\n\n        return train_loss,train_correct\n\n    def valid_epoch(self, epoch):\n        \n        valid_loss = 0.0\n        y_tr_true, y_tr_pred= [], []\n        \n        model.eval()\n        with torch.no_grad():\n            for i, data in enumerate(tqdm(self.testloader, desc=f'Epoch {epoch + 1}/{self.epochs}', unit='batch')):\n                \n                images, labels = data\n                y_tr_true.extend(labels) # collect all training labels\n                images,labels = images.to(device),labels.to(device)\n                \n                output = model(images)\n                loss=loss_fn(output,labels)\n                valid_loss+=loss.item()*images.size(0)\n                scores, predictions = torch.max(output.data,1)\n                y_tr_pred.extend(prediction)\n        \n        val_correct = accuracy_score(y_tr_true, y_tr_pred)\n\n        return valid_loss,val_correct\n    \n    def train(self,\n              train_data,\n              test_data,\n              epochs=1,\n              k_folds=5,\n              delta = 0,\n              patience = 10,\n              verbose = False):\n\n        self.epochs = epochs\n        self.train_dataloader = train_data\n        self.test_dataloader = test_data\n\n\n        # Create empty results dictionary\n        results = {\"epoch\":[],\n                \"train_loss\": [],\n                \"train_acc\": [],\n                \"test_loss\": [],\n                \"test_acc\": []\n        }\n\n        # Define the K-fold Cross Validator\n        kfold =  StratifiedKFold(n_splits= k_folds, shuffle=True, random_state=42)\n        \n        self.dataset = ConcatDataset([train_data, test_data])\n        labels = [t[1] for t in self.dataset]\n\n        # Make sure model on target device\n        self.model.to(self.device)\n\n        # Loop through training and testing steps for a number of epochs\n        print('--------------------------------')\n\n        # K-fold Cross Validation model evaluation\n        for fold, (train_ids, test_ids) in enumerate(kfold.split(self.dataset, labels)):\n            print('Fold {}'.format(fold + 1))\n            \n            # Sample elements randomly from a given list of ids, no replacement.\n            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n            \n            # Define data loaders for training and testing data in this fold\n            self.trainloader = torch.utils.data.DataLoader(\n                              self.dataset, \n                              batch_size = BATCH_SIZE,\n                              sampler = train_subsampler)\n\n            self.testloader = torch.utils.data.DataLoader(\n                              self.dataset,\n                              batch_size = BATCH_SIZE, \n                              sampler = test_subsampler)\n\n            for epoch in range(self.epochs):\n                train_loss, train_correct = self.train_epoch(epoch)\n                test_loss, test_correct = self.valid_epoch(epoch)\n\n                train_loss = train_loss / len(self.trainloader.sampler)\n                train_acc = train_correct * 100\n                test_loss = test_loss / len(self.testloader.sampler)\n                test_acc = test_correct * 100\n                                                                                                            \n\n                # Print out what's happening\n                print(\n                f\"Epoch: {epoch+1} | \"\n                f\"train_loss: {train_loss:.4f} | \"\n                f\"train_acc: {train_acc:.4f} | \"\n                f\"test_loss: {test_loss:.4f} | \"\n                f\"test_acc: {test_acc:.4f}\"\n                )\n\n                # Update results dictionary\n                results[\"epoch\"].append(epoch+1)\n                results[\"train_loss\"].append(train_loss)\n                results[\"test_loss\"].append(test_loss)\n                results[\"train_acc\"].append(train_acc)\n                results[\"test_acc\"].append(test_acc)\n\n\n\n                if self.early_stopping:\n                    self.check_early_stop(test_loss, delta, verbose, patience, epoch)\n                    if self.early_stop:\n                        print(\"Early Stopping\")\n                        break\n\n        # Mark the run as finished\n#         wandb.finish()\n        # Return the filled results at the end of the epochs\n        return results\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.301033Z","iopub.execute_input":"2024-02-11T13:18:19.301332Z","iopub.status.idle":"2024-02-11T13:18:19.326585Z","shell.execute_reply.started":"2024-02-11T13:18:19.301305Z","shell.execute_reply":"2024-02-11T13:18:19.325803Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss(reduction='sum') # computes the cross entropy loss between input logits and target.\n\noptimizer = torch.optim.Adam(model.parameters(), lr = ALPHA)\n\n# Start the timer\nfrom timeit import default_timer as timer\nstart_time = timer()\n\n# Setup training and save the results\nEngine = KFold(model=model, loss_fn=loss_fn, optimizer=optimizer, device=device, early_stopping=True)\nhistory = Engine.train(train_data=train_data, test_data=test_data, epochs=EPOCH, verbose=True, patience = 5)\n\n# End the timer and print out how long it took\nend_time = timer()\nprint(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-02-11T13:18:19.327604Z","iopub.execute_input":"2024-02-11T13:18:19.327837Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"--------------------------------\nFold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbc9ff85695c4100adb06504b8ecd4db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b56a18eadd2d4e518c8479e11dd470e0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | train_loss: 21.4956 | train_acc: 68.9369 | test_loss: 12.9697 | test_acc: 83.2669\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a8843fdeaf4ceba3cc0c8d58824cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca3e00c4e111477d98469ee437b52190"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2 | train_loss: 9.4562 | train_acc: 89.0698 | test_loss: 11.9663 | test_acc: 86.9854\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93fb8749e5e444f981ef6a612a47d12a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c129097d5f4210a983ec70b1e6d451"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3 | train_loss: 3.5903 | train_acc: 96.6445 | test_loss: 11.2308 | test_acc: 88.7118\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b7ab5245e5a43ab9e2ab2e62aa86875"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"639d8ac1e626498a853f2c285dd4ac9c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 4 | train_loss: 2.0359 | train_acc: 97.7741 | test_loss: 15.1761 | test_acc: 86.4542\nEarly stopping counter: 1 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7815609c9c547939285ed5d41602cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7a43b9187e4af196958d55772c82f2"}},"metadata":{}},{"name":"stdout","text":"Epoch: 5 | train_loss: 2.0594 | train_acc: 98.2060 | test_loss: 11.6231 | test_acc: 90.0398\nEarly stopping counter: 2 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5b36258c124f0d953f697f0635695c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8610e502ef5483e83f501d6d3976c4d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 6 | train_loss: 1.6162 | train_acc: 98.5050 | test_loss: 12.4227 | test_acc: 88.3134\nEarly stopping counter: 3 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302b7a1957144d1d807d143075f1face"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ac6f5dc7314e0686148c78fb848010"}},"metadata":{}},{"name":"stdout","text":"Epoch: 7 | train_loss: 1.0663 | train_acc: 98.9369 | test_loss: 11.9155 | test_acc: 89.6414\nEarly stopping counter: 4 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb5969358854310be7bafef6789f3f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dea9784b82bd4c76aacae320d36ceb0f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 8 | train_loss: 0.9030 | train_acc: 99.0033 | test_loss: 11.8951 | test_acc: 89.1102\nEarly stopping counter: 5 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6095d1c73335440094277ff5346e4841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002c07de0d1e40c9a7452e691288cbc0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 9 | train_loss: 1.1781 | train_acc: 98.5050 | test_loss: 13.4514 | test_acc: 87.9150\nEarly stopping counter: 6 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6af702971e451bbdeac23b6af3c101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de707d8838741ba863cab43a39c53aa"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | train_loss: 0.7920 | train_acc: 99.2691 | test_loss: 14.1649 | test_acc: 88.3134\nEarly stopping counter: 7 out of 10\nFold 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cea307d4e5747a691bbe74493c584e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d9193323eb437f9bb84fd4891dd693"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | train_loss: 6.0169 | train_acc: 93.8538 | test_loss: 2.4024 | test_acc: 97.0784\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39b7c747fbc14d52b3fede425ca42a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7eb1d8d73949dc822943b87bbef20a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2 | train_loss: 1.9748 | train_acc: 97.9402 | test_loss: 0.9230 | test_acc: 99.2032\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2661b4bc9c4091bd33e095f08451e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bd1b1c60d1e4516b818ff57d71a2a3d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3 | train_loss: 0.9976 | train_acc: 99.0365 | test_loss: 1.8231 | test_acc: 98.5392\nEarly stopping counter: 1 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600c43c11c2a45b7a6889b9d54a8652d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae37abeeda0740dca788472b7e1c39ea"}},"metadata":{}},{"name":"stdout","text":"Epoch: 4 | train_loss: 0.3847 | train_acc: 99.7342 | test_loss: 1.2419 | test_acc: 99.2032\nEarly stopping counter: 2 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c752cb59e53f4b51b2899581b30d87c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9b13f0a4bd4ab4b5366dc7ba4eeb2b"}},"metadata":{}},{"name":"stdout","text":"Epoch: 5 | train_loss: 0.7314 | train_acc: 99.3023 | test_loss: 1.4229 | test_acc: 99.0704\nEarly stopping counter: 3 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3538a888db704f75a989133c2de4ddf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7dc7f3fb379406a9b824019adb3c1fd"}},"metadata":{}},{"name":"stdout","text":"Epoch: 6 | train_loss: 0.7286 | train_acc: 99.2691 | test_loss: 1.5603 | test_acc: 98.4064\nEarly stopping counter: 4 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9d13af6c3f444ab465277f3c7d7348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"124cea9cc90749069810f7ba8027d74c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 7 | train_loss: 0.5646 | train_acc: 99.4684 | test_loss: 1.8661 | test_acc: 98.2736\nEarly stopping counter: 5 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732cf74610874df881e1bee625e8a46e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc2901228654f2896a3e022e2f75e08"}},"metadata":{}},{"name":"stdout","text":"Epoch: 8 | train_loss: 0.5223 | train_acc: 99.6013 | test_loss: 1.5302 | test_acc: 98.4064\nEarly stopping counter: 6 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"988f3197dc724d53a2820ed97426f08c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cef4cd785a84f3f81e8e710f04dabf9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 9 | train_loss: 0.9544 | train_acc: 98.9701 | test_loss: 2.7353 | test_acc: 96.9456\nEarly stopping counter: 7 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0684a7ff562047c0b51a6d2b950c39da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00c6fb36e68402b99b27a93b70b8f89"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | train_loss: 0.9492 | train_acc: 99.0365 | test_loss: 1.5070 | test_acc: 98.8048\nEarly stopping counter: 8 out of 10\nFold 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bad1ac337024a7c8395bab545c3e712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb4abf97a9d4049a2fa5a0a27d4cfc1"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | train_loss: 1.4825 | train_acc: 98.6711 | test_loss: 1.0728 | test_acc: 99.3360\nEarly stopping counter: 9 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"541b583e096f4279a2a52f83d41d19b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f711e3223204bbeac3992023fb16fc8"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2 | train_loss: 1.2585 | train_acc: 98.6711 | test_loss: 0.3961 | test_acc: 99.6016\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cec8939b3b4493397b32c6213692070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2031281892a48aa8e201be2d13f2476"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3 | train_loss: 1.1094 | train_acc: 98.8372 | test_loss: 0.4738 | test_acc: 99.4688\nEarly stopping counter: 1 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c671857e0564d2c9ac404ec861f4387"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b25bf009d1e4b109b367a3d07334499"}},"metadata":{}},{"name":"stdout","text":"Epoch: 4 | train_loss: 0.4633 | train_acc: 99.5681 | test_loss: 0.2292 | test_acc: 99.7344\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e192c21ee43b47e19d722edc4886dc43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62aa77d5def4a5e9a7e71cbef0de17a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 5 | train_loss: 0.2269 | train_acc: 99.8339 | test_loss: 0.5206 | test_acc: 99.2032\nEarly stopping counter: 1 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36624fca9e24d64bdfda1f32ee19952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f87b26a80f4244b060a9f3dd0d0b29"}},"metadata":{}},{"name":"stdout","text":"Epoch: 6 | train_loss: 0.1509 | train_acc: 99.9336 | test_loss: 0.2912 | test_acc: 99.7344\nEarly stopping counter: 2 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b870c4f7f745898e974532655d40ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455a434db162402587986698746ed0bd"}},"metadata":{}},{"name":"stdout","text":"Epoch: 7 | train_loss: 0.2477 | train_acc: 99.7342 | test_loss: 0.7348 | test_acc: 99.2032\nEarly stopping counter: 3 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cefcc5482fc4921ac9e8f22eb550c4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7d5cfd7b464d9e8fcfdc08cdc76e58"}},"metadata":{}},{"name":"stdout","text":"Epoch: 8 | train_loss: 0.1599 | train_acc: 99.8339 | test_loss: 0.4253 | test_acc: 99.7344\nEarly stopping counter: 4 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a7e0d1513f464394096f8dbef731b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4875056d115744359f3f904fb3d8b1ee"}},"metadata":{}},{"name":"stdout","text":"Epoch: 9 | train_loss: 0.1991 | train_acc: 99.8339 | test_loss: 0.3796 | test_acc: 99.6016\nEarly stopping counter: 5 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ba7bd31a314c4f805ed6e76332c992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c348da0b39e42afb6cb6d6261419ce0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10 | train_loss: 0.8087 | train_acc: 99.2359 | test_loss: 3.3389 | test_acc: 96.4143\nEarly stopping counter: 6 out of 10\nFold 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9af26c9c3f6e4ec0af5a857381c9418d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fed82d2eb5d49baab2717426922b149"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | train_loss: 1.7398 | train_acc: 98.1069 | test_loss: 0.8253 | test_acc: 99.2021\nEarly stopping counter: 7 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e1db40e3ed49729e818f652d9f79a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59c54dfce454b2290bceae2ba15acb7"}},"metadata":{}},{"name":"stdout","text":"Epoch: 2 | train_loss: 1.7377 | train_acc: 98.2730 | test_loss: 0.8948 | test_acc: 99.3351\nEarly stopping counter: 8 out of 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed5b8d565a1a479aae87d91cd7b4e4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/24 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c276793b464fbe9ead096d7d951024"}},"metadata":{}},{"name":"stdout","text":"Epoch: 3 | train_loss: 0.9322 | train_acc: 99.0037 | test_loss: 0.1773 | test_acc: 100.0000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/95 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bad6c586e39147b18250791e276e3f1c"}},"metadata":{}}]},{"cell_type":"code","source":"\navg_train_loss = np.mean(history['train_loss'])\navg_test_loss = np.mean(history['test_loss'])\navg_train_acc = np.mean(history['train_acc'])\navg_test_acc = np.mean(history['test_acc'])\n\nprint('Performance of {} fold cross validation'.format(K_FOLDS))\nprint(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_train_acc,avg_test_acc)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}